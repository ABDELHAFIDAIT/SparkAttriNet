{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4787aeb",
   "metadata": {},
   "source": [
    "## <center style=\"color:blue;\">**SparkAttriNet**</center>\n",
    "\n",
    "Dans le secteur bancaire, anticiper la perte de clients est essentiel pour réduire le taux d’attrition et renforcer la fidélisation. \n",
    "\n",
    "Ce projet exploite la puissance de PySpark pour analyser de grands volumes de données, MLlib pour entraîner un modèle prédictif, MongoDB pour stocker les données transformées, et Streamlit pour visualiser les résultats et faciliter la prise de décision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04b0756",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### <span style=\"color:green;\">**Configuration et Initialisation du Pipeline Spark :**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabadb37",
   "metadata": {},
   "source": [
    "#### <span style=\"color:orange;\">**1. Apache Spark :**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441681eb",
   "metadata": {},
   "source": [
    "##### **1.1. Définition :**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28630eda",
   "metadata": {},
   "source": [
    "``Apache Spark`` est un framework open-source conçu pour le traitement distribué de données à grande échelle.\n",
    "Il permet d’exécuter des calculs complexes sur des volumes massifs de données en les répartissant sur plusieurs machines d’un cluster.\n",
    "\n",
    "``Spark`` fonctionne en mémoire (in-memory computing), ce qui le rend beaucoup plus rapide que les systèmes traditionnels comme Hadoop MapReduce."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8dc4f6",
   "metadata": {},
   "source": [
    "##### **1.2. A quoi sert ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cb5e50",
   "metadata": {},
   "source": [
    "``Spark`` sert principalement à analyser, transformer et traiter de grandes quantités de données de manière efficace et parallèle.\n",
    "Il est utilisé pour des tâches variées :\n",
    "\n",
    "- **Traitement de données massives (Big Data) :** nettoyage, agrégation, transformation de fichiers volumineux.\n",
    "\n",
    "- **Analyse exploratoire et statistique** à grande échelle.\n",
    "\n",
    "- **Machine Learning** via la bibliothèque intégrée ``MLlib``, pour entraîner des modèles sur d’énormes datasets.\n",
    "\n",
    "- **Traitement de flux en temps réel** (avec ``Spark Streaming``) pour suivre des événements en continu.\n",
    "\n",
    "En résumé, ``Spark`` est une plateforme unifiée qui permet de manipuler, analyser et modéliser des données massives, tout en offrant des performances élevées grâce à son exécution distribuée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f154ba6",
   "metadata": {},
   "source": [
    "#### <span style=\"color:orange;\">**2. Créer une session Spark optimisée :**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb51658",
   "metadata": {},
   "source": [
    "La ``SparkSession`` est le point d’entrée principal pour interagir avec ``Spark``.\n",
    "\n",
    "C’est le cerveau de chaque application ``Spark`` :\n",
    "\n",
    "elle permet de créer des DataFrames, d’exécuter des requêtes SQL, de lire et écrire des fichiers (CSV, Parquet, JSON, etc.), et de configurer un cluster.\n",
    "\n",
    "```js\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "        .appName(\"AttriSpark - Client Attrition Prediction\")\n",
    "        .master(\"local[14]\")\n",
    "        .config(\"spark.driver.memory\", \"24g\")\n",
    "        .config(\"spark.executor.memory\", \"24g\")\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"32\")\n",
    "        .config(\"spark.memory.fraction\", \"0.7\")\n",
    "        .config(\"spark.memory.storageFraction\", \"0.5\")\n",
    "        .config(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "        .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a930c69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SparkAttriNet - Prédiction de l'Attrition Client Bancaire\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04015ae7",
   "metadata": {},
   "source": [
    "#### <span style=\"color:orange;\">**3. Vérifier la version de Spark. :**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d15959a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session Créée avec Succès !\n",
      "Version Spark : 4.0.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Spark Session Créée avec Succès !\")\n",
    "print(f\"Version Spark : {spark.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08760e15",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### <span style=\"color:green;\">**Chargement et Inspection des Données :**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f429c4c",
   "metadata": {},
   "source": [
    "#### <span style=\"color:orange;\">**1. Charger les données :**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3c81743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données Chargées avec Succès !\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\n",
    "    \"../data/raw/data.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "print(\"Données Chargées avec Succès !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115811f9",
   "metadata": {},
   "source": [
    "#### <span style=\"color:orange;\">**2. Afficher le Schéma des Colonnes :**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42792a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- RowNumber: integer (nullable = true)\n",
      " |-- CustomerId: integer (nullable = true)\n",
      " |-- Surname: string (nullable = true)\n",
      " |-- CreditScore: integer (nullable = true)\n",
      " |-- Geography: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Tenure: integer (nullable = true)\n",
      " |-- Balance: double (nullable = true)\n",
      " |-- NumOfProducts: integer (nullable = true)\n",
      " |-- HasCrCard: integer (nullable = true)\n",
      " |-- IsActiveMember: integer (nullable = true)\n",
      " |-- EstimatedSalary: double (nullable = true)\n",
      " |-- Exited: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6dcb53",
   "metadata": {},
   "source": [
    "#### <span style=\"color:orange;\">**3. Afficher un Extrait des Données :**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e67b36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+\n",
      "|RowNumber|CustomerId| Surname|CreditScore|Geography|Gender|Age|Tenure|  Balance|NumOfProducts|HasCrCard|IsActiveMember|EstimatedSalary|Exited|\n",
      "+---------+----------+--------+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+\n",
      "|        1|  15634602|Hargrave|        619|   France|Female| 42|     2|      0.0|            1|        1|             1|      101348.88|     1|\n",
      "|        2|  15647311|    Hill|        608|    Spain|Female| 41|     1| 83807.86|            1|        0|             1|      112542.58|     0|\n",
      "|        3|  15619304|    Onio|        502|   France|Female| 42|     8| 159660.8|            3|        1|             0|      113931.57|     1|\n",
      "|        4|  15701354|    Boni|        699|   France|Female| 39|     1|      0.0|            2|        0|             0|       93826.63|     0|\n",
      "|        5|  15737888|Mitchell|        850|    Spain|Female| 43|     2|125510.82|            1|        1|             1|        79084.1|     0|\n",
      "+---------+----------+--------+-----------+---------+------+---+------+---------+-------------+---------+--------------+---------------+------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
