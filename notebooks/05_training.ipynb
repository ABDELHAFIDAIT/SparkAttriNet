{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e99a3018",
   "metadata": {},
   "source": [
    "## <center style=\"color:blue;\">**SparkAttriNet**</center>\n",
    "\n",
    "Dans le secteur bancaire, anticiper la perte de clients est essentiel pour réduire le taux d’attrition et renforcer la fidélisation. \n",
    "\n",
    "Ce projet exploite la puissance de PySpark pour analyser de grands volumes de données, MLlib pour entraîner un modèle prédictif, MongoDB pour stocker les données transformées, et Streamlit pour visualiser les résultats et faciliter la prise de décision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcba32f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### <span style=\"color:green;\">**Chargement des Données Nécessaire :**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbd69e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_features</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1.0732410343916199, -1.0189022035876123, -0.3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1.0732410343916199, 1.623344785208039, -0.449...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1.0732410343916199, -1.0189022035876123, -1.6...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1.0732410343916199, -1.0189022035876123, 0.54...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1.0732410343916199, 1.623344785208039, 2.1985...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15913</th>\n",
       "      <td>[-0.9965472758999997, -0.9764411941798411, -0....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15914</th>\n",
       "      <td>[-0.04330050202358865, -0.387549623658877, 0.1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15915</th>\n",
       "      <td>[-0.4823130063121688, -0.057920548926326754, -...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15916</th>\n",
       "      <td>[-0.27250713995341386, -1.0189022035876123, 1....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15917</th>\n",
       "      <td>[-0.6710042271854935, 0.3022212908102134, 2.04...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15918 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         scaled_features  Exited\n",
       "0      [1.0732410343916199, -1.0189022035876123, -0.3...       1\n",
       "1      [1.0732410343916199, 1.623344785208039, -0.449...       0\n",
       "2      [1.0732410343916199, -1.0189022035876123, -1.6...       1\n",
       "3      [1.0732410343916199, -1.0189022035876123, 0.54...       0\n",
       "4      [1.0732410343916199, 1.623344785208039, 2.1985...       0\n",
       "...                                                  ...     ...\n",
       "15913  [-0.9965472758999997, -0.9764411941798411, -0....       1\n",
       "15914  [-0.04330050202358865, -0.387549623658877, 0.1...       1\n",
       "15915  [-0.4823130063121688, -0.057920548926326754, -...       1\n",
       "15916  [-0.27250713995341386, -1.0189022035876123, 1....       1\n",
       "15917  [-0.6710042271854935, 0.3022212908102134, 2.04...       1\n",
       "\n",
       "[15918 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "df = joblib.load(\"../utils/df_scaled.pkl\")\n",
    "train_df = joblib.load(\"../utils/train_df.pkl\")\n",
    "test_df = joblib.load(\"../utils/test_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701281b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(\n",
    "    featuresCol=\"scaled_features\",\n",
    "    labelCol=\"Exited\",\n",
    "    maxIter=100,\n",
    "    regParam=0.01\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
